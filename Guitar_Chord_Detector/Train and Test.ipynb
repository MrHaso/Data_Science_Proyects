{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61afa4aa",
   "metadata": {},
   "source": [
    "# This Notebook will be used to train and test a CNN-Model that will be built from scratch with the intention of not using pre-trained models\n",
    "## Author: MrHaso 2022 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d115a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fa350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub \n",
    "from tensorflow.keras.layers import MaxPooling2D, Input, Conv2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e16b8",
   "metadata": {},
   "source": [
    "### Create Train/Test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d5661",
   "metadata": {},
   "source": [
    "#### Create Array of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6643b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "chords = [\"No_Chord\",\"Am\",\"B\",\"C\",\"D\",\"Em\",\"F\",\"G\"]\n",
    "X = []\n",
    "for folder in chords:\n",
    "    output_path = \"Images/class_\"+folder+\"/\"\n",
    "    for path in os.listdir(output_path):\n",
    "        if os.path.isfile(os.path.join(output_path, path)):\n",
    "            im = cv2.imread(os.path.join(output_path, path))\n",
    "            X.append(im)\n",
    "X = np.array(X)\n",
    "print(X[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d1791",
   "metadata": {},
   "source": [
    "#### Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c729289",
   "metadata": {},
   "outputs": [],
   "source": [
    "chords = [\"No_Chord\",\"Am\",\"B\",\"C\",\"D\",\"Em\",\"F\",\"G\"]\n",
    "labels = []\n",
    "for folder in chords:\n",
    "    output_path = \"Images/class_\"+folder+\"/\"\n",
    "    for path in os.listdir(output_path):\n",
    "        if os.path.isfile(os.path.join(output_path, path)):\n",
    "            labels.append(folder)\n",
    "\n",
    "y = pd.DataFrame(labels)\n",
    "y = pd.factorize(y[0])[0].astype(np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba243f",
   "metadata": {},
   "source": [
    "#### Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e57ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = len(set(y_train))\n",
    "print(f\"We have {K} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0072da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_im = 34\n",
    "plt.imshow(X_test[sample_im]);\n",
    "print(y_test[sample_im])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c601d99",
   "metadata": {},
   "source": [
    "### Create CNN-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97177cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_CNN():\n",
    "    i = Input(shape=X_train[0].shape)\n",
    "    x = Conv2D(64, (3,3), strides=2, activation=\"relu\")(i)\n",
    "    x = Conv2D(128, (3,3), strides=2, activation=\"relu\")(x)\n",
    "    x = Conv2D(256, (3,3), strides=2, activation=\"relu\")(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(2048, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(K, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(i,x)\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ec71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_complex_CNN():\n",
    "    i = Input(shape=X_train[0].shape)\n",
    "    x = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(i)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(256, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(2048, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(K, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(i,x)\n",
    "    model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    \n",
    "    batch_size= 32\n",
    "    data_generator = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.1,\n",
    "                                                                     height_shift_range=0.1,\n",
    "                                                                     horizontal_flip=True)\n",
    "    data_generator.fit(X_train)\n",
    "    train_generator = data_generator.flow(X_train,y_train,batch_size)\n",
    "    steps_per_epoch = X_train.shape[0] // batch_size\n",
    "    \n",
    "    return model, train_generator, steps_per_epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_checkpoint = \"training_1/cp.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(path_checkpoint)\n",
    "\n",
    "save_model = tf.keras.callbacks.ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
    "                                                  patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = build_simple_CNN()\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_model, train_generator, steps_per_epoch = build_complex_CNN()\n",
    "\n",
    "complex_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc58bd3",
   "metadata": {},
   "source": [
    "### Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_r = simple_model.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[save_model,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b975028",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_r = complex_model.fit(train_generator,validation_data=(X_test,y_test),steps_per_epoch=steps_per_epoch,epochs=50,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c09d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(simple_r.history[\"loss\"],label=\"simple loss\")\n",
    "plt.plot(simple_r.history[\"val_loss\"],label=\"simple val_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(simple_r.history[\"accuracy\"],label=\"simple acc\")\n",
    "plt.plot(simple_r.history[\"val_accuracy\"],label=\"simple val_acc\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b083895",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(complex_r.history[\"loss\"],label=\"complex loss\")\n",
    "plt.plot(complex_r.history[\"val_loss\"],label=\"complex val_loss\")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8aa7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(complex_r.history[\"accuracy\"],label=\"complex acc\")\n",
    "plt.plot(complex_r.history[\"val_accuracy\"],label=\"comlpex val_acc\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b03ff1",
   "metadata": {},
   "source": [
    "### Live Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc587f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = build_CNN()\n",
    "\n",
    "loss_, accuracy_ = loaded_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * accuracy_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa647656",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_weights(path_checkpoint)\n",
    "\n",
    "loss_, accuracy_ = loaded_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * accuracy_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09682ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "loaded_model.save('saved_model/loaded_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[24]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_test[24]\n",
    "y = np.expand_dims(x, axis=0)\n",
    "predictions = complex_model.predict(y)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d06018",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels=[0,1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 24\n",
    "print(predictions)\n",
    "print(f\"Max value (probability of prediction): {np.max(predictions)}\")\n",
    "print(f\"Sum: {np.sum(predictions)}\")\n",
    "print(f\"Max index: {np.argmax(predictions)}\")\n",
    "print(f\"Predicted label: {unique_labels[np.argmax(predictions)]}\")\n",
    "print(f\"Correct label: {y_test[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chords = [\"No_Chord\",\"Am\",\"B\",\"C\",\"D\",\"Em\",\"F\",\"G\"]\n",
    "\n",
    "# Setup camera attributes to take pictures with HD-USB Cam \n",
    "cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cam.set(10,150)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30.0)\n",
    "cam.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('m','j','p','g'))\n",
    "cam.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M','J','P','G'))\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "size=(64,64)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cam.read()\n",
    "    frame = frame[0:120,0:120]\n",
    "    \n",
    "    frame2 = cv2.resize(frame,size)\n",
    "    frame = cv2.flip(frame,1)\n",
    "    frame2 = np.expand_dims(frame2, axis=0)\n",
    "    frame3 = cv2.resize(frame,(480,480))\n",
    "    res = simple_model.predict(frame2)\n",
    "    cv2.putText(frame3,chords[np.argmax(res)],(20,50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 8, cv2.LINE_AA)\n",
    "    \n",
    "\n",
    "    cv2.imshow(\"CAM\",frame3)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49f8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
